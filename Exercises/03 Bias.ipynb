{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01edb69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "be139c0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89efd4b1",
   "metadata": {},
   "source": [
    "## Topic 3: Bias\n",
    "\n",
    "****\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "****\n",
    "\n",
    "#### Give three real-world examples of different types of cognitive bias.\n",
    "****\n",
    "\n",
    "Cognitive biases are unconscious errors in thinking that result from our brain’s efforts to simplify the incredibly complex world in which we live. As we can't always evaluate every detail when we form our thoughts and descisions we create mental shortcuts which lead to bias. Confirmation bias, hindsight bias, self-serving bias, anchoring bias, availability bias, the framing effect, and inattentional blindness are some of the most common examples of cognitive bias. Another example is the false consensus effect. Cognitive biases have direct implications on our safety, our interactions with others, and the way we make judgments and decisions in our daily lives. Although these biases are unconscious, there are small steps we can take to train our minds to adopt a new pattern of thinking and mitigate the effects of these biases.[https://www.simplypsychology.org/cognitive-bias.html]\n",
    "\n",
    "Three examples of cognitive bias are:\n",
    "\n",
    "##### Confirmation Bias\n",
    "Confirmation bias is where we tend to listen or tune into information that confirms our existing beliefs. Through this bias, people are inclined to prefer information that reinforces the things they already think or believe and we tend to ignore any data that would contradict those beiefs. \n",
    "\n",
    "A real world example of confirmation bias occurred in the 1998 study by Andrew Wakefield linking the MMR vaccine to autism. Seeking to support his hypothesis it was found Wakefield manipulated the data and ignored much of the research that contradicted his beliefs. As a result of the finding the study was subsequently retracted from the British Medical Journal in 2010. Wakefield's confirmation bias fueled his desire to establish a link to regressive autism - a disproven claim that still affects the medical community today. [https://pubmed.ncbi.nlm.nih.gov/32057491/]\n",
    "\n",
    "##### Anchoring Bias\n",
    "Anchoring bias is the tendency to be overly influenced by pre-existing information or the first piece of information we find researching a topic. We are \"anchored\" by the first information available to us. All subsequent information is compared to the initial information we received.\n",
    "\n",
    "Anchoring bias is used in the real world particularly in marketing to affect how we shop. We tend to base the value of goods by the cost of the first item we see. Psychologists Brian Wansink, Robert Kent, and Stephen Hoch studied how multiple unit pricing increased supermarket sales. For example, “ On Sale, 4 Rolls of Bathroom Tissue for $2 ” versus “ On Sale, $0.50 per roll ” In this particular experiment, the multiple unit pricing performed 40% better than the single unit pricing, even though the sale value is exactly the same. The brain used the number four as the anchor.[https://theagencyarsenal.com/3-examples-of-the-anchoring-rule-in-marketing/] Supermarket brands like ALDI, use this technique to target their competitors. In their ‘Like’ marketing campaign they use price comparison to present brands with a higher price first. They do this to anchor the consumer’s view on price before presenting the ALDI option, which is of course much lower.[https://thebehavioursagency.com/anchoring-in-marketing/]\n",
    "\n",
    "##### Gamblers Fallacy\n",
    "Sometimes also referred to as the Monte Carlo Fallacy; the gambler’s fallacy describes our belief that the probability of a random event occurring in the future is influenced by previous instances of that type of event. It can affect how we assess the probability of a future event by looking at past events that are similar. According to economists Hersh Shefrin and Meir Statman, investors tend to hold onto stocks that have depreciated and sell stocks that have appreciated. They call this a “general disposition to sell winners too early and hold losers too long.[https://thedecisionlab.com/biases/gamblers-fallacy] The most famous example of gambler’s fallacy and where it got it's other name is from the roulette tables of a Monte Carlo casino in 1913. For the last 10 spins of the roulette wheel, the ball had landed on black therefore the gamblers thought a red was long overdue and they started betting against black. But the ball kept on landing on black. It was only after 26 consecutive blacks that the ball finally landed on red and the streak came to an end. By this time, the lgamblers had made significant losses.\n",
    "\n",
    "Another more real life example came from a study in 1796, where Pierre-Simon Laplace described in A Philosophical Essay on Probabilities the ways in which men calculated their probability of having sons: \"I have seen men, ardently desirous of having a son, who could learn only with anxiety of the births of boys in the month when they expected to become fathers. Imagining that the ratio of these births to those of girls ought to be the same at the end of each month, they judged that the boys already born would render more probable the births next of girls.\" The expectant fathers feared that if more sons were born in the surrounding community, then they themselves would be more likely to have a daughter. This essay by Laplace is regarded as one of the earliest descriptions of the fallacy.Likewise, after having multiple children of the same sex, some parents may erroneously believe that they are due to have a child of the opposite sex.[https://en.wikipedia.org/wiki/Gambler%27s_fallacy]\n",
    "\n",
    "****\n",
    "### Exercise 2\n",
    "\n",
    "****\n",
    "\n",
    "#### Show that the difference between the standard deviation calculations is greatest for small sample sizes.\n",
    "\n",
    "****\n",
    "Standard deviation measures the variability (taking the data values and the mean into account) in a data set. \n",
    "\n",
    "The formula for standard deviation (SD), where x represents a data value, y represents the mean, and n represents the sample size:\n",
    "\n",
    "$ SD=\\sqrt{\\frac{\\sum(x-y^2)}{n-1}} $\n",
    "\n",
    "Standard deviation is important as it allows us to assess the level of stability in the data. If there is a relatively high standard deviation, then it is considered the variability in the data is high and if the standard deviation is low, then there is low variability.\n",
    "\n",
    "The standard deviation we obtain by sampling a distribution is itself not absolutely accurate, both for mathematical reasons (explained here by the confidence interval) and for practical reasons of measurement (measurement error). The mathematical effect can be described by the confidence interval or CI.\n",
    "\n",
    "To show how a small sample size will increase the standard deviation we will look at some examples: \n",
    "\n",
    "A small population of N = 2 has only 1 degree of freedom for estimating the standard deviation. The result is that a 95% CI of the SD runs from 0.45 × SD to 31.9 × SD; the factors here are as follows:\n",
    "\n",
    "$ {\\displaystyle \\Pr \\left(q_{\\frac {\\alpha }{2}}<k{\\frac {s^{2}}{\\sigma ^{2}}}<q_{1-{\\frac {\\alpha }{2}}}\\right)=1-\\alpha ,}{\\displaystyle \\Pr \\left(q_{\\frac {\\alpha }{2}}<k{\\frac {s^{2}}{\\sigma ^{2}}}<q_{1-{\\frac {\\alpha }{2}}}\\right)=1-\\alpha ,} $\n",
    "where $ {\\displaystyle q_{p}}{\\displaystyle q_{p}} $ is the p-th quantile of the chi-square distribution with k degrees of freedom, and $ {\\displaystyle 1-\\alpha }1-\\alpha $  is the confidence level. \n",
    "\n",
    "This is equivalent to the following:\n",
    "\n",
    "$ {\\displaystyle \\Pr \\left(k{\\frac {s^{2}}{q_{1-{\\frac {\\alpha }{2}}}}}<\\sigma ^{2}<k{\\frac {s^{2}}{q_{\\frac {\\alpha }{2}}}}\\right)=1-\\alpha .}{\\displaystyle \\Pr \\left(k{\\frac {s^{2}}{q_{1-{\\frac {\\alpha }{2}}}}}<\\sigma ^{2}<k{\\frac {s^{2}}{q_{\\frac {\\alpha }{2}}}}\\right)=1-\\alpha .} $\n",
    "With k = 1,  $ {\\displaystyle q_{0.025}=0.000982}{\\displaystyle q_{0.025}=0.000982} $ and $ {\\displaystyle q_{0.975}=5.024}{\\displaystyle q_{0.975}=5.024} $. \n",
    "The reciprocals of the square roots of these two numbers give us the factors 0.45 and 31.9 given above.\n",
    "\n",
    "A larger population of N = 10 has 9 degrees of freedom for estimating the standard deviation. The same computations as above give us in this case a 95% CI running from 0.69 × SD to 1.83 × SD. So even with a sample population of 10, the actual SD can still be almost a factor 2 higher than the sampled SD. \n",
    "\n",
    "For a sample population N=100, this is down to 0.88 × SD to 1.16 × SD. To be more certain that the sampled SD is close to the actual SD we need to sample a large number of points.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
